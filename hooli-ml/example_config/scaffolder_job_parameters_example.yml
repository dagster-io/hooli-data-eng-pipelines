# Example: Databricks bundle configuration with job-level parameters
# This demonstrates how the scaffolder extracts job-level parameters and preserves job parameter references

bundle:
  name: ml_pipeline_with_job_parameters

variables:
  experiment_settings: "mlflow://databricks"
  catalog_map: "dev.catalog"
  log_level: "INFO"
  llm_calls: "enabled"
  git_sha: "{{ git_sha }}"
  output_bucket_name: "my-data-bucket"
  orchestrator_job_run_id: "{{ run_id }}"
  environment: "{{ env }}"
  profiler_enabled: "false"

targets:
  dev:
    default: true
    variables:
      env: "dev"
      catalog: "dev"
  prod:
    variables:
      env: "prod"
      catalog: "prod"

include:
  - resources/jobs_with_parameters.yml 